{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e47e9d4-afef-4c87-bb60-e8db6084d738",
   "metadata": {},
   "source": [
    "Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5764007-feff-4ff1-9a3a-4ab52ee24aff",
   "metadata": {},
   "source": [
    "1) What is Simple Linear Regression ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3242866d-5397-47ab-a655-5d25bb25af55",
   "metadata": {},
   "source": [
    "Simple linear regression is a statistical method used to model the relationship between two variables. It assumes that one variable (the dependent or response variable) can be predicted from\n",
    "another variable (the independent or predictor variable) using a straight line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c8bc5b-f23b-411e-8d1c-faedf59444a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95b1bef2-af0a-4e33-bded-a4ce0213bd1b",
   "metadata": {},
   "source": [
    "2) What are the key assumptions of Simple Linear Regression ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b501d915-b7ff-4907-adda-1784c3563258",
   "metadata": {},
   "source": [
    "1. Linearity\n",
    "\n",
    "The relationship between the independent variable \n",
    "ùë•\n",
    "x and the dependent variable \n",
    "ùë¶\n",
    "y should be linear. This means that a straight line is an appropriate model for the data.\n",
    "\n",
    "2. Independence\n",
    "\n",
    "The observations (data points) should be independent of one another. In other words, the value of \n",
    "ùë¶\n",
    "y at one point should not influence or be related to the value of \n",
    "ùë¶\n",
    "y at another point.\n",
    "\n",
    "3. Homoscedasticity\n",
    "    \n",
    "The variance of the errors (or residuals) should be constant across all values of \n",
    "ùë•\n",
    "x. In simple terms, the spread or \"scatter\" of data points around the regression line should be roughly the same for all values of \n",
    "ùë•\n",
    "x. If the spread increases or decreases as \n",
    "ùë•\n",
    "x changes, the data exhibits heteroscedasticity.\n",
    "\n",
    "4. Normality of Residuals\n",
    "\n",
    "The residuals (the differences between the observed and predicted values of \n",
    "ùë¶\n",
    "y) should be approximately normally distributed. This assumption is important for making valid inferences (like hypothesis testing) about the regression coefficients.\n",
    "\n",
    "5. No Perfect Multicollinearity \n",
    "(for multiple regression, not as relevant for simple linear regression)\n",
    "Although this is more important in multiple regression (when you have more than one predictor), it's generally assumed that \n",
    "ùë•\n",
    "x is not perfectly correlated with any other independent variables in the model.\n",
    "\n",
    "7. No Autocorrelation\n",
    "\n",
    "The residuals should not be correlated with one another. This is particularly important in time-series data, where consecutive data points could influence each other (autocorrelation). If residuals are correlated, it suggests a model specification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122691c7-eef2-47cf-bdc9-a0bdd022378f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b7a91b4-6a14-4101-a332-ba89ec7a3a7c",
   "metadata": {},
   "source": [
    "3) What does the coefficient m represent in the equation Y=mX+c ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e53af3-f136-442d-9d58-42beeb45acfd",
   "metadata": {},
   "source": [
    "In the equation \n",
    "ùëå\n",
    "=ùëö\n",
    "ùëã\n",
    "+\n",
    "ùëê\n",
    "   \n",
    "    Y=mX+c, which is the equation of a straight line, the coefficient \n",
    "ùëö\n",
    "m represents the slope of the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c3fc0c-8202-4751-b7be-343c96b2a01a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cf79496-b4f6-47d7-b3c2-73ec1529afa2",
   "metadata": {},
   "source": [
    "4) What does the intercept c represent in the equation Y=mX+c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8310cd7-787e-423d-9a74-95bdbc6a722b",
   "metadata": {},
   "source": [
    "In the equation \n",
    "ùëå\n",
    "=ùëö\n",
    "ùëã\n",
    "+\n",
    "ùëê\n",
    "\n",
    "Y=mX+c, the intercept \n",
    "ùëê\n",
    "c represents the y-intercept of the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd2dbe-6f31-45fa-9f43-7fda20f54de5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0075b527-dad5-4c05-aa97-d933b824ead1",
   "metadata": {},
   "source": [
    "5) How do we calculate the slope m in Simple Linear Regression ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de54f66c-8306-4460-ac7e-29344a8ed25a",
   "metadata": {},
   "source": [
    "In simple linear regression, the slope \n",
    "ùëö\n",
    "m (also known as \n",
    "ùõΩ\n",
    "1\n",
    "Œ≤ \n",
    "1\n",
    "‚Äã\n",
    " ) is calculated using the following formula:"
   ]
  },
  {
   "attachments": {
    "00ac15b6-f2e9-4ab5-a993-3aa94509b63f.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "c60ff08e-d9b5-468d-9887-d1f39b5c2331",
   "metadata": {},
   "source": [
    "![Screenshot 2025-01-28 125028.png](attachment:00ac15b6-f2e9-4ab5-a993-3aa94509b63f.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4952b98c-0582-479a-9bbe-245ad3de68b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bc25b4e-6211-4736-af80-542bd1dd21ce",
   "metadata": {},
   "source": [
    "6) What is the purpose of the least squares method in Simple Linear Regression ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a634a9d1-1b9f-440f-8af5-4b97776b0858",
   "metadata": {},
   "source": [
    "\n",
    "The least squares method in simple linear regression is used to find the best-fitting line (the regression line) that minimizes the difference between the observed data points and the predicted values from the model. The goal is to find the line that minimizes the sum of the squared differences (residuals) between the observed values \n",
    "ùëå\n",
    "Y and the values predicted by the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4a9447-acb0-42ba-bb7e-88eded297530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae17c943-b5ba-4a38-987d-6cc4de9c7ee5",
   "metadata": {},
   "source": [
    "7) How is the coefficient of determination (R¬≤) interpreted in Simple Linear Regression ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccd0de6-acde-4541-82d5-d12537ff7157",
   "metadata": {},
   "source": [
    "The coefficient of determination (\n",
    "ùëÖ\n",
    "2\n",
    "R \n",
    "2\n",
    " ) is a key measure in simple linear regression that tells you how well the regression line fits the data. It is a value between 0 and 1, and it is interpreted as the proportion of the variance in the dependent variable \n",
    "ùëå\n",
    "Y that is explained by the independent variable \n",
    "ùëã\n",
    "X in the model.\n",
    "\n",
    "Interpretation of \n",
    "ùëÖ\n",
    "2\n",
    "\n",
    "R \n",
    "2\n",
    " :\n",
    "( R^2 = 1:**\n",
    "\n",
    "A value of 1 means that the regression line perfectly fits the data. All the data points lie exactly on the line, and there is no unexplained variance.\n",
    "\n",
    "( R^2 = 0:**\n",
    "\n",
    "A value of 0 means that the regression model does not explain any of the variance in the dependent variable \n",
    "ùëå\n",
    "Y. The data points are completely random and not correlated with \n",
    "ùëã\n",
    "X.\n",
    "\n",
    "0 < \n",
    "ùëÖ\n",
    "2\n",
    "< 1:**\n",
    "\n",
    "Any value between 0 and 1 represents a proportion of the variance explained by the model. For example, \n",
    "ùëÖ\n",
    "2\n",
    "=0.75\n",
    "R \n",
    "2\n",
    " =0.75 means that 75% of the variation in \n",
    "ùëå\n",
    "Y is explained by \n",
    "ùëã\n",
    "X, and the remaining 25% is due to factors not captured by the model (i.e., the residuals or errors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba05ba6-c371-457e-90de-de5b397e9a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f870fff6-b59c-486e-8a6a-778ed0153592",
   "metadata": {},
   "source": [
    "8) What is Multiple Linear Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469890e5-85a0-420b-8ad5-3ec7629d7b03",
   "metadata": {},
   "source": [
    "Multiple linear regression is an extension of simple linear regression that models the relationship between a dependent variable and two or more independent variables. Instead of predicting \n",
    "ùëå\n",
    "Y based on just one predictor \n",
    "ùëã\n",
    "X (like in simple linear regression), multiple linear regression uses multiple predictors to predict \n",
    "ùëå\n",
    "Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f46cce-fd45-4cbf-9e9c-8ebfc48c7515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06ef0021-8588-4a1d-b6f6-11b0dfa8bf73",
   "metadata": {},
   "source": [
    "9) What is the main difference between Simple and Multiple Linear Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a06236-37f5-4279-91cf-8953adfab68c",
   "metadata": {},
   "source": [
    "The main difference between simple linear regression and multiple linear regression lies in the number of independent variables (predictors) used to predict the dependent variable.\n",
    "\n",
    " Number of Independent Variables (Predictors):\n",
    " \n",
    "Simple Linear Regression:\n",
    "\n",
    " Uses one independent variable to predict the dependent variable.\n",
    "\n",
    "ùëå\n",
    "=ùõΩ\n",
    "0\n",
    "+\n",
    "ùõΩ\n",
    "1\n",
    "ùëã\n",
    "+\n",
    "ùúñ\n",
    "\n",
    "In simple linear regression, there's only one predictor \n",
    "ùëã\n",
    "X that is used to explain or predict the outcome \n",
    "ùëå\n",
    "Y.\n",
    "\n",
    "Multiple Linear Regression:\n",
    "\n",
    "Uses two or more independent variables to predict the dependent variable.\n",
    "\n",
    "ùëå\n",
    "=ùõΩ\n",
    "0\n",
    "+\n",
    "ùõΩ\n",
    "1\n",
    "ùëã\n",
    "1\n",
    "+\n",
    "ùõΩ\n",
    "2\n",
    "ùëã\n",
    "2\n",
    "+\n",
    "‚ãØ\n",
    "+\n",
    "ùõΩ\n",
    "ùëù\n",
    "ùëã\n",
    "ùëù\n",
    "+\n",
    "ùúñ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682b004b-eaa4-44e0-8cdd-89f02b1f13e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a98b720-65d0-4194-bb1f-172e2e63b6d0",
   "metadata": {},
   "source": [
    "10) What are the key assumptions of Multiple Linear Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2ccafa-18b4-4642-8a53-6c38752f8015",
   "metadata": {},
   "source": [
    "\n",
    "Multiple linear regression makes several key assumptions to ensure that the model provides reliable and valid results. These assumptions are crucial because if they are violated, the estimates of the model parameters may become biased or inefficient.\n",
    "\n",
    "Linearity: The relationship between predictors and the outcome is linear.\n",
    "\n",
    "Independence of Errors: Residuals are independent.\n",
    "\n",
    "Homoscedasticity: Constant variance of residuals.\n",
    "\n",
    "Normality of Errors: Residuals are normally distributed.\n",
    "\n",
    "No Perfect Multicollinearity: Predictors should not be highly correlated.\n",
    "\n",
    "No Significant Outliers: No extreme data points with high influence.\n",
    "\n",
    "Additivity: The effect of each predictor is additive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc804a28-c6e2-44b8-b3cd-4d49a9023d23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7ee8c7f-96ce-4010-a38c-5971cf3c2b2d",
   "metadata": {},
   "source": [
    "11) What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336b4ec8-ebbf-45a5-9abb-5a3263d5dac0",
   "metadata": {},
   "source": [
    "\n",
    "Heteroscedasticity refers to a situation in regression analysis where the variance of the errors (residuals) is not constant across all levels of the independent variables. In other words, as the values of the independent variables (or the predicted values of the dependent variable) change, the spread or \"scatter\" of the residuals increases or decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b46dd0-58a9-4692-981a-1649f7f22547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "160d6dd1-5258-4ed2-91d0-2638164478d1",
   "metadata": {},
   "source": [
    "12) How can you improve a Multiple Linear Regression model with high multicollinearity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1843f264-beb2-4277-800f-65d7d2d9608e",
   "metadata": {},
   "source": [
    "Multicollinearity in multiple linear regression occurs when two or more independent variables (predictors) are highly correlated with each other. This can cause issues because it makes it difficult to estimate the individual effect of each predictor on the dependent variable. High multicollinearity leads to unstable estimates of the regression coefficients, inflating their standard errors, and making hypothesis tests unreliable.\n",
    "\n",
    "Remove one of the correlated variables.\n",
    "\n",
    "Combine correlated variables into a single composite variable.\n",
    "\n",
    "Use Principal Component Analysis (PCA) to create uncorrelated components.\n",
    "\n",
    "Apply Ridge or Lasso Regression to shrink the coefficients and reduce the impact of multicollinearity.\n",
    "\n",
    "Increase sample size to provide a clearer view of relationships.\n",
    "\n",
    "Center or standardize variables to improve model performance.\n",
    "\n",
    "Check for multicollinearity using VIF or the correlation matrix and address accordingly.\n",
    "\n",
    "Use stepwise regression to select relevant predictors.\n",
    "\n",
    "Apply domain knowledge to decide which predictors to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bd9ffb-28e3-4bb7-93e9-0dbb91374029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c74a308-b3ce-4d1d-91f1-6589641edd6d",
   "metadata": {},
   "source": [
    "13) What are some common techniques for transforming categorical variables for use in regression models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c04076-5965-4f1f-9269-7250e8957f58",
   "metadata": {},
   "source": [
    "One-Hot Encoding: Best for nominal variables with few categories.\n",
    "\n",
    "Label Encoding: Simple and efficient for ordinal variables or when the number of categories is small.\n",
    "\n",
    "Ordinal Encoding: Use for ordinal data with an inherent order.\n",
    "    \n",
    "Binary Encoding: Compact and efficient, especially for high-cardinality data.\n",
    "    \n",
    "Frequency Encoding: Replace categories with their frequency of occurrence; works well for high-cardinality variables.\n",
    "                                                                                     \n",
    "Target Encoding: Encode categories based on the target variable's mean for each category; use with caution to avoid overfitting.\n",
    "\n",
    "Hashing: Efficient for very high-cardinality variables but can lead to collisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ef7e3a-5893-44fe-85b5-ede38a52b32f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "842aaf4a-4645-4aa2-ba26-dd0153138cba",
   "metadata": {},
   "source": [
    "14) What is the role of interaction terms in Multiple Linear Regression ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6966d7c-0b24-430e-8263-5cf60a352ffa",
   "metadata": {},
   "source": [
    "In Multiple Linear Regression, an interaction term is used to capture the combined effect of two or more independent variables on the dependent variable, where the effect of one predictor on the outcome depends on the value of another predictor. Interaction terms allow us to model more complex relationships between predictors and the dependent variable that cannot be captured by simply adding them individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb89893-22cc-4a3a-a256-fd34d24f6349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85fa5440-cc21-442b-81ff-b8c537eef0b9",
   "metadata": {},
   "source": [
    "15) How can the interpretation of intercept differ between Simple and Multiple Linear Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42dad78-7358-46fc-b3e8-c6d2ab8edd30",
   "metadata": {},
   "source": [
    "1. Interpretation of Intercept in Simple Linear Regression:\n",
    "\n",
    "In Simple Linear Regression, there is only one independent variable, so the model has the form:\n",
    "\n",
    "ùëå\n",
    "=ùõΩ\n",
    "0\n",
    "+\n",
    "ùõΩ\n",
    "1\n",
    "ùëã\n",
    "+\n",
    "ùúñ\n",
    "\n",
    "Interpretation: The intercept \n",
    "\n",
    "ùõΩ\n",
    "0\n",
    "‚Äã\n",
    "  represents the expected value of the dependent variable (Y) when the independent variable \n",
    "ùëã is zero.\n",
    "\n",
    "Example: If you're modeling house price (Y) based on square footage (X), the intercept \n",
    "ùõΩ\n",
    "0\n",
    "‚Äã\n",
    "  would represent the estimated house price when the square footage is 0 (i.e., when there is no house). While this may not always make practical sense, mathematically, it provides a starting point for the relationship between \n",
    "ùëå\n",
    "Y and \n",
    "ùëã\n",
    "X.\n",
    "\n",
    "2. Interpretation of Intercept in Multiple Linear Regression:\n",
    "\n",
    "In Multiple Linear Regression, the model involves multiple independent variables:\n",
    "\n",
    "ùëå\n",
    "=ùõΩ\n",
    "0\n",
    "+\n",
    "ùõΩ\n",
    "1\n",
    "ùëã\n",
    "1\n",
    "+\n",
    "ùõΩ\n",
    "2\n",
    "ùëã\n",
    "2\n",
    "+\n",
    "‚ãØ\n",
    "+\n",
    "ùõΩ\n",
    "ùëò\n",
    "ùëã\n",
    "ùëò\n",
    "+\n",
    "ùúñ\n",
    "\n",
    "Interpretation: The intercept \n",
    "ùõΩ\n",
    "0\n",
    "Œ≤ \n",
    "0\n",
    "‚Äã\n",
    "  represents the expected value of the dependent variable (Y) when all independent variables (\n",
    "ùëã\n",
    "1\n",
    ",\n",
    "ùëã\n",
    "2\n",
    ",\n",
    ".\n",
    ".\n",
    ".\n",
    ",\n",
    "ùëã\n",
    "ùëò\n",
    "X \n",
    "1\n",
    "‚Äã\n",
    " ,X \n",
    "2\n",
    "‚Äã\n",
    " ,...,X \n",
    "k\n",
    "‚Äã\n",
    " ) are equal to zero.\n",
    "\n",
    "Example: Suppose you're modeling house price (Y) based on square footage (X_1), number of bedrooms (X_2), and age of the house (X_3). The intercept \n",
    "ùõΩ\n",
    "0\n",
    "Œ≤ \n",
    "0\n",
    "‚Äã\n",
    "  would represent the estimated house price when all three predictors are zero ‚Äî i.e., when the house has zero square footage, zero bedrooms, and zero age (effectively, a hypothetical scenario where no house exists). While this may not always be realistic, it serves as the baseline from which the effects of the predictors are measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4148b8ed-74b9-4cb1-8b36-22bb6ab9c459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cac1ed6-e681-4100-8607-aacc82cc8a02",
   "metadata": {},
   "source": [
    "16) What is the significance of the slope in regression analysis, and how does it affect predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef54a66-908e-4997-8860-d5ff4d279596",
   "metadata": {},
   "source": [
    "1. Interpretation of the Slope:\n",
    "   \n",
    "In Simple Linear Regression:\n",
    "\n",
    "\n",
    "The model is typically represented as:\n",
    "ùëå\n",
    "=ùõΩ\n",
    "0\n",
    "+\n",
    "ùõΩ\n",
    "1\n",
    "ùëã\n",
    "+\n",
    "ùúñ\n",
    "‚Äã\n",
    "  (the slope) represents the amount by which \n",
    "ùëå\n",
    "Y changes when \n",
    "ùëã\n",
    "X changes by one unit.\n",
    "Example: If \n",
    "ùõΩ\n",
    "1\n",
    "=5\n",
    "in a model predicting salary based on years of experience, it means that for each additional year of experience, the salary is expected to increase by 5 units (e.g., $5,000 or 5%, depending on the scale).\n",
    "In Multiple Linear Regression:\n",
    "\n",
    "The model is extended to include multiple predictors:\n",
    "ùëå\n",
    "=ùõΩ\n",
    "0\n",
    "+\n",
    "ùõΩ\n",
    "1\n",
    "ùëã\n",
    "1\n",
    "+\n",
    "ùõΩ\n",
    "2\n",
    "ùëã\n",
    "2\n",
    "+\n",
    "‚ãØ\n",
    "+\n",
    "ùõΩ\n",
    "ùëò\n",
    "ùëã\n",
    "ùëò\n",
    "+\n",
    "ùúñ\n",
    "\n",
    "Each \n",
    "ùõΩ\n",
    "ùëñ\n",
    "‚Äã\n",
    "  represents the effect of the corresponding independent variable \n",
    "ùëã\n",
    "ùëñ\n",
    "‚Äã\n",
    "  on the dependent variable \n",
    "ùëå\n",
    "Y, while holding the other predictors constant.\n",
    "Example: In a model predicting house price based on square footage and number of bedrooms, \n",
    "ùõΩ\n",
    "1\n",
    "‚Äã\n",
    "  would represent how the price changes with square footage, assuming the number of bedrooms stays constant, and \n",
    "ùõΩ\n",
    "2\n",
    "‚Äã\n",
    "  would represent how the price changes with the number of bedrooms, assuming square footage stays constant.\n",
    "  \n",
    "2. Significance of the Slope:\n",
    "\n",
    "The slope is significant in regression analysis for the following reasons:\n",
    "\n",
    "Magnitude of the Effect: The magnitude of the slope indicates the strength of the relationship between the predictor and the dependent variable. Larger absolute values of the slope mean a stronger influence of the predictor on the outcome.\n",
    "\n",
    "Example: In predicting exam scores based on hours of study, a slope of 3 suggests a stronger relationship than a slope of 0.5, meaning for every additional hour of study, the exam score increases more with a slope of 3.\n",
    "Direction of the Relationship: The sign of the slope (positive or negative) tells you the direction of the relationship.\n",
    "\n",
    "Positive Slope: If the slope is positive, it indicates that as the independent variable increases, the dependent variable also increases (a direct relationship).\n",
    "Negative Slope: If the slope is negative, it indicates that as the independent variable increases, the dependent variable decreases (an inverse relationship).\n",
    "Predictive Power: The slope directly affects the predictions made by the regression model. For a given value of the independent variable \n",
    "ùëã\n",
    "X, the predicted value of \n",
    "ùëå\n",
    "Y is calculated as:\n",
    "\n",
    "ùëå\n",
    "^\n",
    "=ùõΩ\n",
    "0\n",
    "+\n",
    "ùõΩ\n",
    "1\n",
    "ùëã\n",
    "\n",
    "Example: If you are predicting someone's income based on years of experience, the slope tells you how much income is predicted to change when experience increases. A positive slope suggests income increases with experience, while a negative slope would suggest a decrease in income with more experience.\n",
    "\n",
    "3. Impact of the Slope on Predictions:\n",
    "   \n",
    "The slope has a direct impact on the predicted values in regression:\n",
    "\n",
    "If the slope is positive: The predicted value of \n",
    "ùëå\n",
    "Y increases as \n",
    "ùëã\n",
    "X increases. For example, if you're predicting sales based on advertising expenditure, a positive slope means that higher spending on ads is expected to result in higher sales.\n",
    "\n",
    "If the slope is negative: The predicted value of \n",
    "ùëå\n",
    "Y decreases as \n",
    "ùëã\n",
    "X increases. For example, if you're predicting temperature based on altitude, a negative slope would suggest that as altitude increases, temperature decreases.\n",
    "\n",
    "Predictions with Multiple Variables: In Multiple Linear Regression, the slope coefficients tell you the change in \n",
    "ùëå\n",
    "Y for each individual predictor, while controlling for other variables.\n",
    "\n",
    "Example: If you're predicting house prices based on both square footage and the number of bedrooms, the slope for square footage represents how much the price increases per additional square foot, holding the number of bedrooms constant. The slope for the number of bedrooms tells you how much the price changes for each additional bedroom, holding square footage constant.\n",
    "\n",
    "4. Significance Testing of the Slope:\n",
    "   \n",
    "To determine whether a slope is statistically significant (i.e., whether the relationship between the predictor and outcome is not due to random chance), we typically use hypothesis testing. Specifically:\n",
    "\n",
    "The null hypothesis is that the slope \n",
    "ùõΩ\n",
    "1\n",
    "=0\n",
    "(there is no effect).\n",
    "The alternative hypothesis is that \n",
    "ùõΩ\n",
    "1\n",
    "‚â†\n",
    "0\n",
    "(there is a significant effect).\n",
    "Using a t-test and a p-value, we can test if the slope is significantly different from zero. If the p-value is below a threshold (typically 0.05), the slope is considered statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f1d710-555b-4eed-89a6-7db0554ff84c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "639462b4-d6a4-4d4e-b12f-e72b9b0c236a",
   "metadata": {},
   "source": [
    "17) How does the intercept in a regression model provide context for the relationship between variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f112e9cf-e9c5-47fb-980e-62a34edb8bee",
   "metadata": {},
   "source": [
    "1. Baseline or Reference Point for Predictions:\n",
    "   \n",
    "The intercept can be thought of as the value of the dependent variable when all predictors are zero.\n",
    "Example: In a simple linear regression model like:\n",
    "ùëå\n",
    "=ùõΩ\n",
    "0\n",
    "+\n",
    "ùõΩ\n",
    "1\n",
    "ùëã\n",
    "+\n",
    "ùúñ\n",
    "                              \n",
    "ùõΩ\n",
    "0\n",
    "‚Äã\n",
    "  represents the predicted value of \n",
    "ùëå\n",
    "Y when \n",
    "ùëã\n",
    "=0\n",
    "If you are modeling house price (Y) based on square footage (X), then \n",
    "ùõΩ\n",
    "0\n",
    "  would represent the estimated price of the house when the square footage is zero (a hypothetical scenario where there is no house).\n",
    "    \n",
    "2. Interpretation of the Intercept:\n",
    "    \n",
    "In some cases, the intercept has a meaningful, practical interpretation. For example, in a model predicting salary based on years of experience, if the intercept is 30,000, it suggests that a person with zero years of experience would have a baseline salary of $30,000 (if other variables are held constant).\n",
    "In other cases, the intercept may not have a direct or realistic interpretation, especially if setting the predictors to zero leads to an unrealistic or impossible situation (like zero square footage or zero education level). In such cases, the intercept is often seen as more of a mathematical necessity for fitting the model, rather than a meaningful real-world value.\n",
    "                                                                                                                                                                                                                                         \n",
    "3. Contextual Meaning in Multiple Regression:\n",
    "                                                                                                                                                                                                                                         \n",
    "In Multiple Linear Regression, where there are multiple independent variables, the intercept represents the predicted value of the dependent variable when all independent variables are zero. The interpretation can depend on the nature of the variables:\n",
    "\n",
    "Example: Suppose you are modeling house price (Y) using square footage (X‚ÇÅ), number of bedrooms (X‚ÇÇ), and age of the house (X‚ÇÉ):\n",
    "ùëå\n",
    "=ùõΩ\n",
    "0\n",
    "+\n",
    "ùõΩ\n",
    "1\n",
    "ùëã\n",
    "1\n",
    "+\n",
    "ùõΩ\n",
    "2\n",
    "ùëã\n",
    "2\n",
    "+\n",
    "ùõΩ\n",
    "3\n",
    "ùëã\n",
    "3\n",
    "+\n",
    "ùúñ\n",
    "              \n",
    "The intercept \n",
    "ùõΩ\n",
    "0\n",
    "‚Äã\n",
    "  would represent the expected house price when:\n",
    "Square footage = 0 (no house),\n",
    "Number of bedrooms = 0 (no bedrooms),\n",
    "Age of the house = 0 (a brand new house with no years).\n",
    "While the intercept might not be meaningful in a literal sense (since such a house does not exist), it serves as a baseline from which the effects of the independent variables are measured. This baseline is crucial because it anchors the predictions of the model.\n",
    "\n",
    "              \n",
    "4. Understanding the Relationship Between Variables:\n",
    "              \n",
    "In Simple Linear Regression: The intercept helps you understand the starting point or initial value of the dependent variable when the independent variable is zero. This provides a context for understanding how changes in the independent variable impact the dependent variable.\n",
    "Example: If you're modeling sales (Y) as a function of advertising expenditure (X) and the intercept is 1000, it means that if no money is spent on advertising (X = 0), the baseline sales would be 1000 units.\n",
    "In Multiple Linear Regression: The intercept still provides the baseline value, but now it reflects the situation where all predictors are set to zero. The interpretation can be more complex because the intercept is influenced by the specific combination of predictors.\n",
    "Example: In a model predicting employee performance (Y) based on years of experience (X‚ÇÅ) and education level (X‚ÇÇ), the intercept tells you the expected performance when both experience and education are zero (which might not be a practical scenario, but it's the starting point for the model).\n",
    "                                                                                                                                                                                                                  \n",
    "5. Use of Intercept in Practical Contexts:\n",
    "                                                                                                                                                                                  \n",
    "The intercept helps in setting expectations for the baseline behavior of the outcome:\n",
    "\n",
    "If the intercept is large, it suggests that the dependent variable tends to have a higher baseline value when all predictors are at zero.\n",
    "If the intercept is close to zero (or negative), it suggests that the dependent variable tends to have a smaller baseline value.\n",
    "                                           \n",
    "6. What Happens if the Intercept is Not Meaningful:\n",
    "                                           \n",
    "In some cases, especially in multiple regression, the intercept might not represent a realistic scenario. For example:\n",
    "\n",
    "If you are modeling salary based on years of experience and education level, and the intercept is 0, this might imply that someone with 0 years of experience and 0 education has a salary of 0, which is unrealistic. In such cases, the intercept serves mainly as a mathematical anchor for the model, not as a meaningful prediction.\n",
    "                                           \n",
    "7. Handling Non-Realistic Intercepts:\n",
    "                                           \n",
    "Sometimes, to improve the interpretability or realism of the model, the intercept may be forced to be zero, or the model might exclude the intercept in certain contexts (though this is less common). This may happen when you believe that the dependent variable should logically be zero when all predictors are zero, or when zero is a meaningful reference point.\n",
    "\n",
    "Example: If you're predicting fuel efficiency based on weight of the car, it might make sense to exclude the intercept if you believe a car with zero weight would logically have zero fuel efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478ce6fd-8f59-432b-a81b-2310665bf085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8921f020-cbd6-4cdf-b846-057c960f1ce8",
   "metadata": {},
   "source": [
    "18) What are the limitations of using R¬≤ as a sole measure of model performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c720fb3d-7460-477d-949b-f42704d47cc2",
   "metadata": {},
   "source": [
    "1. R¬≤ Doesn't Indicate Causality:\n",
    "\n",
    "Limitation: R¬≤ measures how well the independent variables explain the variability in the dependent variable, but it does not imply a causal relationship between them. A high R¬≤ value may suggest a strong correlation, but this does not mean that the independent variables cause the changes in the dependent variable.\n",
    "Example: You might find a high R¬≤ between the number of ice creams sold and the temperature, but that doesn‚Äôt mean that ice cream sales cause the temperature to rise. It could be the reverse (warmer weather causes more ice cream sales), or both could be affected by a third variable (like season).\n",
    "\n",
    "2. R¬≤ Can Be Misleading in Complex Models:\n",
    "\n",
    "Limitation: In models with many predictors, R¬≤ can increase even if the new predictors are not truly helpful in explaining the dependent variable. This is because adding more variables to the model always increases the R¬≤, regardless of whether those variables improve the model‚Äôs predictive power or not.\n",
    "Example: If you add irrelevant variables (e.g., predictors that are not related to the outcome), R¬≤ can still increase, even though the model is overfitting the data.\n",
    "\n",
    "3. Overfitting:\n",
    "\n",
    "Limitation: High R¬≤ values can sometimes be a sign of overfitting, where the model fits the noise in the data rather than the underlying relationship. Overfitting happens when the model is too complex and captures random fluctuations in the data, leading to poor generalization to new, unseen data.\n",
    "Example: A model with 15 predictors might have an R¬≤ of 0.95, but it could be overfitted. The model may work well on the training data but fail to predict future observations accurately.\n",
    "\n",
    "4. R¬≤ Doesn't Penalize for Model Complexity:\n",
    "\n",
    "Limitation: R¬≤ does not penalize the model for being too complex (i.e., having too many predictors). This can lead to a situation where you add many variables to improve R¬≤, but this doesn't necessarily improve the model‚Äôs predictive accuracy or generalizability.\n",
    "Solution: Adjusted R¬≤ can be a better alternative in this case because it adjusts for the number of predictors in the model, providing a more reliable estimate of model fit that penalizes the addition of unnecessary variables.\n",
    "\n",
    "5. R¬≤ Cannot Handle Nonlinear Relationships:\n",
    "\n",
    "Limitation: R¬≤ assumes that the relationship between the dependent and independent variables is linear. If the true relationship is nonlinear, R¬≤ can be low even if the model fits the data well in a nonlinear sense.\n",
    "Example: If the relationship between the variables is quadratic or exponential, a linear regression model may have a low R¬≤, even though it could still be a reasonable approximation for the data.\n",
    "\n",
    "6. No Information on the Model's Error:\n",
    "\n",
    "Limitation: R¬≤ does not provide any information about the size or distribution of the model's errors. A model with a high R¬≤ could still have large residuals (errors) in certain regions, meaning that it might make large mistakes in specific areas of the data.\n",
    "Solution: Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and residual analysis are better suited for understanding the error distribution and how well the model is performing across different subsets of the data.\n",
    "\n",
    "7. R¬≤ Can Be Inflated by Outliers:\n",
    "\n",
    "Limitation: The R¬≤ value can be highly sensitive to outliers or extreme values in the data. A few large or unusual data points can disproportionately affect the R¬≤ value, making the model appear better or worse than it actually is.\n",
    "Example: In a dataset with a few extreme outliers, the R¬≤ might suggest a good fit even though the model performs poorly for the majority of the data.\n",
    "\n",
    "8. R¬≤ Can Be Low in Some Useful Models:\n",
    "\n",
    "Limitation: A low R¬≤ value does not necessarily mean that the model is unhelpful. In some cases, even a model with a low R¬≤ can still provide useful predictions or insights, especially if it‚Äôs based on highly variable data or if the goal is not to explain all the variance but rather to make reasonable predictions or provide actionable insights.\n",
    "Example: In forecasting or predictive models, especially with noisy data or in situations where many factors influence the outcome (such as predicting stock prices or disease outbreaks), a lower R¬≤ could still be acceptable if the model provides useful predictions.\n",
    "\n",
    "9. R¬≤ Doesn't Capture the Direction of the Relationship:\n",
    "\n",
    "Limitation: R¬≤ doesn‚Äôt tell you anything about the sign of the relationship between variables (whether it's positive or negative). It simply measures how much variance in the dependent variable is explained by the independent variables.\n",
    "Example: Two models could have the same R¬≤ value, but one might have a positive relationship between predictors and the outcome, while the other could have a negative relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ede702-3e82-4734-944b-5ff9aaf1fe59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "221ea8fc-0d32-4723-bc22-d6ab4fb87b1c",
   "metadata": {},
   "source": [
    "19) How would you interpret a large standard error for a regression coefficient?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98057399-3538-4ce9-b9b4-9af7eff3adbf",
   "metadata": {},
   "source": [
    "1. Imprecision of the Estimate:\n",
    "\n",
    "The standard error (SE) measures the variability of the regression coefficient estimate across different samples of the data. If the standard error is large, it means the coefficient estimate might fluctuate a lot if you were to repeat the analysis on different samples. This makes the estimate less reliable.\n",
    "Example: If you're estimating the relationship between house price and square footage, a large standard error for the coefficient on square footage means that the effect of square footage on house price is uncertain. The actual value of the effect might vary significantly in different datasets.\n",
    "\n",
    "2. Impact on Statistical Significance:\n",
    "\n",
    "A large standard error typically leads to a larger p-value (for a given coefficient), meaning that the coefficient is less likely to be statistically significant.\n",
    "To test whether the coefficient is significantly different from zero, we calculate the t-statistic as:\n",
    "ùë°\n",
    "=Coefficient¬†Estimate\n",
    "Standard¬†Error\n",
    "t= \n",
    "Standard¬†Error\n",
    "Coefficient¬†Estimate\n",
    "‚Äã\n",
    " \n",
    "If the standard error is large, the t-statistic will be smaller, making it less likely that we will reject the null hypothesis that the coefficient is zero (no effect).\n",
    "Example: If the coefficient estimate is 2 but the standard error is 10, the t-statistic will be \n",
    "2\n",
    "10\n",
    "=0.2\n",
    "10\n",
    "2\n",
    "‚Äã\n",
    " =0.2, which likely results in a high p-value, indicating that the effect of the predictor is not statistically significant.\n",
    "\n",
    "3. Possible Causes of a Large Standard Error:\n",
    "Several factors can contribute to a large standard error:\n",
    "\n",
    "Small sample size: When the sample size is small, there's more variability in the estimate of the regression coefficient, leading to a larger standard error.\n",
    "High multicollinearity: If the predictors in the model are highly correlated with each other (multicollinearity), it becomes difficult to distinguish their individual effects on the dependent variable, which increases the standard errors of the coefficients.\n",
    "Example: If you're modeling house price based on both square footage and number of rooms, these two variables might be highly correlated, leading to high standard errors for their coefficients.\n",
    "Large variability in the data: If the data has high variance or is noisy, it can make it harder to precisely estimate the relationship between the predictor and the outcome, leading to larger standard errors.\n",
    "Model misspecification: If the model does not correctly capture the underlying relationships in the data (e.g., using linear regression when the relationship is nonlinear), the estimated coefficients may be unstable, resulting in large standard errors.\n",
    "\n",
    "4. Interpretation in Context:\n",
    "   \n",
    "Less confidence in the coefficient: A large standard error means that you have less confidence in the coefficient estimate. This implies that the predictor associated with the coefficient may not have a reliable impact on the dependent variable, or the model may not be capturing the true relationship.\n",
    "\n",
    "5. Uncertain practical significance:\n",
    "Even if the coefficient is large, a large standard error makes it hard to say with certainty whether that predictor has a meaningful effect in practical terms. The high variability suggests that the result may not hold up in other samples or future observations.\n",
    "Example: If you're estimating the effect of advertising budget on sales, and the coefficient for advertising has a large standard error, you might not be able to confidently conclude that advertising expenditure has a consistent impact on sales. A large standard error would suggest that the estimated effect might not be robust or reliable.\n",
    "\n",
    "6. Impact on Confidence Intervals:\n",
    "   \n",
    "The confidence interval (CI) for a regression coefficient is calculated as:\n",
    "CI\n",
    "=Coefficient¬†Estimate\n",
    "¬±\n",
    "(\n",
    "ùë°\n",
    "ùõº\n",
    "/\n",
    "2\n",
    "√ó\n",
    "Standard¬†Error\n",
    ")\n",
    "CI=Coefficient¬†Estimate¬±(t \n",
    "Œ±/2\n",
    "‚Äã\n",
    " √óStandard¬†Error)\n",
    "If the standard error is large, the confidence interval for the coefficient will also be wide, meaning there‚Äôs greater uncertainty about the true value of the coefficient.\n",
    "Example: A coefficient estimate of 5 with a large standard error of 10 would result in a confidence interval like \n",
    " suggesting a lot of uncertainty about the actual effect.\n",
    "\n",
    "8. What to Do with a Large Standard Error:\n",
    "Examine model assumptions: Check if the model is appropriate for the data, and ensure that assumptions such as linearity, homoscedasticity, and independence are met. If the assumptions are violated, this can lead to large standard errors.\n",
    "Increase the sample size: A larger sample size can help reduce the variability in the coefficient estimates and lower the standard error, improving the precision of the estimates.\n",
    "Address multicollinearity: If multicollinearity is present, try removing highly correlated predictors, combining similar variables, or using regularization techniques like Ridge or Lasso regression to reduce the impact of multicollinearity.\n",
    "Consider model simplification: If the model is too complex or contains too many predictors, consider reducing the number of predictors to improve the stability of the coefficient estimates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec81cb3-309f-4356-be56-035df27c2088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d9f679d-d1b0-4907-aeb2-f27d20fac58c",
   "metadata": {},
   "source": [
    "20) How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a47d44-872f-4ccf-b02f-f60c5ae2f9de",
   "metadata": {},
   "source": [
    "Identifying Heteroscedasticity in Residual Plots\n",
    "\n",
    "Residual plots are a common tool for diagnosing heteroscedasticity. Here's how you can identify heteroscedasticity through these plots:\n",
    "\n",
    "Plot the Residuals vs. Fitted Values:\n",
    "\n",
    "In this plot, the x-axis represents the fitted values (predicted values from the model), and the y-axis represents the residuals (the difference between the observed values and the predicted values).\n",
    "What to look for:\n",
    "If the variance of the residuals appears to increase or decrease as the fitted values change, this indicates heteroscedasticity. For example, if the residuals fan out (widen) or contract (narrow) as you move along the x-axis, it suggests that the variability of errors is not constant.\n",
    "If the residuals are scattered randomly around zero with no clear pattern, this suggests homoscedasticity (constant variance).\n",
    "Signs of Heteroscedasticity:\n",
    "\n",
    "Funnel shape:\n",
    "The spread of the residuals increases or decreases as the fitted values increase, creating a cone or funnel shape in the residual plot.\n",
    "Curved patterns: A non-random pattern, such as a \"U\" or \"inverted U\" shape, might suggest the presence of heteroscedasticity, especially when the variability increases or decreases systematically.\n",
    "Example: If you plot the residuals against the fitted values and see a pattern where the residuals are tightly clustered at lower fitted values but spread out more at higher fitted values, this indicates heteroscedasticity.\n",
    "\n",
    "Plot the Residuals vs. an Independent Variable:\n",
    "\n",
    "Another way to identify heteroscedasticity is to plot the residuals against a specific independent variable (predictor).\n",
    "If the variance of the residuals increases or decreases as the value of the independent variable changes, this is an indication of heteroscedasticity.\n",
    "Scale-Location Plot (also called Spread-Location Plot):\n",
    "\n",
    "This plot shows the square root of the standardized residuals against the fitted values.\n",
    "In a well-behaved model, the points should be randomly scattered with no clear pattern. If the points start spreading out or contracting as the fitted values increase, this suggests heteroscedasticity.\n",
    "\n",
    "Why is It Important to Address Heteroscedasticity?\n",
    "\n",
    "Heteroscedasticity can undermine the assumptions of ordinary least squares (OLS) regression and can lead to problems in the analysis:\n",
    "\n",
    "Impact on Statistical Inference:\n",
    "\n",
    "The presence of heteroscedasticity affects the efficiency of the coefficient estimates. Although the coefficients themselves may still be unbiased, the standard errors of the coefficients are likely to be biased. This can lead to incorrect conclusions about the statistical significance of the predictors.\n",
    "Specifically, the estimated standard errors might be too small (leading to false positives ‚Äî Type I errors) or too large (leading to false negatives ‚Äî Type II errors), which can make hypothesis tests unreliable.\n",
    "Incorrect Confidence Intervals:\n",
    "\n",
    "When heteroscedasticity is present, the confidence intervals for the regression coefficients may be too narrow or too wide, providing misleading information about the precision of the estimates.\n",
    "Inefficient Estimation:\n",
    "\n",
    "While OLS regression will still provide unbiased estimates of the coefficients, it will no longer be the most efficient estimator. This means that other methods like Weighted Least Squares (WLS) or robust standard errors would provide more accurate estimates in the presence of heteroscedasticity.\n",
    "Model Misfit:\n",
    "\n",
    "Heteroscedasticity can suggest that the model is not correctly capturing the relationship between the predictors and the dependent variable. It might indicate that a nonlinear relationship exists, or that you should include additional variables or transformations to improve the model fit.\n",
    "\n",
    "How to Address Heteroscedasticity\n",
    "\n",
    "If you detect heteroscedasticity in your residual plots, there are several ways to address it:\n",
    "\n",
    "Transform the Dependent Variable:\n",
    "\n",
    "Sometimes applying a logarithmic or square root transformation to the dependent variable can stabilize the variance of the residuals. For example, if the variance increases with the level of the dependent variable, you could try transforming the dependent variable using \n",
    "log\n",
    "‚Å°\n",
    "(\n",
    "ùëå\n",
    ")\n",
    "log(Y) or \n",
    "ùëå\n",
    "Y\n",
    "‚Äã\n",
    " .\n",
    "Example: If you're modeling income as a function of education level, income may have increasing variance as the values get larger. Applying a log transformation to income might reduce the heteroscedasticity.\n",
    "Use Robust Standard Errors:\n",
    "\n",
    "If transforming the data is not feasible or desirable, you can use robust standard errors (also known as heteroscedasticity-consistent standard errors) to correct for heteroscedasticity in the model. This method adjusts the standard errors to account for non-constant variance without changing the coefficient estimates themselves.\n",
    "Example: In R, you can use the vcovHC function to compute heteroscedasticity-consistent standard errors for linear models.\n",
    "Weighted Least Squares (WLS):\n",
    "\n",
    "In cases of heteroscedasticity, you might consider using Weighted Least Squares regression. In WLS, each observation is given a weight, with the weight typically being the inverse of the variance of the residuals for that observation. This method allows the model to place less emphasis on observations with higher variance and more emphasis on those with lower variance.\n",
    "Check Model Specification:\n",
    "\n",
    "Heteroscedasticity can sometimes arise from incorrect model specification, such as missing relevant variables or using an incorrect functional form (e.g., using linear regression when the relationship is nonlinear). It may help to:\n",
    "Include missing variables,\n",
    "Try nonlinear transformations of the predictors, or\n",
    "Use polynomial or interaction terms if appropriate.\n",
    "Nonlinear Models:\n",
    "\n",
    "If heteroscedasticity results from a nonlinear relationship between the predictors and the dependent variable, you could consider using nonlinear regression models or generalized least squares (GLS) to better model the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8486fc7e-13e2-4c59-83c2-3e48a446d8da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d60259f1-a9b5-48b7-9867-c16b5aba2b07",
   "metadata": {},
   "source": [
    "21) What does it mean if a Multiple Linear Regression model has a high R¬≤ but low adjusted R¬≤\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1111febd-dd53-4e7e-8646-116988e7a5c1",
   "metadata": {},
   "source": [
    "1. Understanding R¬≤ and Adjusted R¬≤:\n",
    "\n",
    "R¬≤ (Coefficient of Determination): R¬≤ measures the proportion of the variance in the dependent variable that is explained by the independent variables. A high R¬≤ means that the model explains a large portion of the variability in the outcome variable.\n",
    "\n",
    "Problem with R¬≤: One limitation of R¬≤ is that it always increases or stays the same when more predictors are added to the model. Even if the new predictors are irrelevant, R¬≤ can still increase, which could give a false impression of a better model fit.\n",
    "Adjusted R¬≤: Adjusted R¬≤ adjusts R¬≤ for the number of predictors in the model. It penalizes the model for including too many irrelevant predictors, making it a more reliable measure of model fit when there are multiple predictors. If you add a variable that improves the model‚Äôs ability to explain the variance, adjusted R¬≤ increases. However, if the added variable does not improve the model significantly, adjusted R¬≤ decreases or stays the same.\n",
    "\n",
    "2. What Does It Mean When R¬≤ is High and Adjusted R¬≤ is Low?:\n",
    "\n",
    "High R¬≤ indicates that the model explains a large portion of the variance in the dependent variable.\n",
    "Low adjusted R¬≤, on the other hand, suggests that adding more predictors to the model has not improved the model‚Äôs explanatory power enough to justify their inclusion. Essentially, the model might be overfitting the data ‚Äî it may have too many predictors, some of which do not contribute meaningfully to explaining the outcome.\n",
    "Overfitting means the model fits the training data very well (resulting in a high R¬≤), but it may not generalize well to new, unseen data. The additional predictors in the model might be capturing noise or random fluctuations rather than the true underlying relationships.\n",
    "\n",
    "3. Causes of a High R¬≤ and Low Adjusted R¬≤:\n",
    "\n",
    "Including Too Many Irrelevant Predictors: If you add predictors that are not truly related to the outcome, R¬≤ will still increase, but adjusted R¬≤ will decrease or show a smaller increase, as it penalizes for the inclusion of non-contributory variables.\n",
    "\n",
    "Example: You might have a dataset where the target variable is influenced by 3 main factors, but you add 5 irrelevant features. R¬≤ may increase simply because of the additional features, but adjusted R¬≤ will lower or increase less because those additional features don‚Äôt help the model.\n",
    "Multicollinearity: High multicollinearity among predictors can artificially inflate R¬≤ because the predictors are highly correlated with each other. This can make the model appear more accurate than it really is. However, adjusted R¬≤ will highlight this issue because the additional variables might not be adding unique explanatory power.\n",
    "\n",
    "Overfitting: Overfitting occurs when the model becomes too complex relative to the amount of data available. The model may explain the training data perfectly, but it could fail to generalize to new data, which is why adjusted R¬≤ decreases (it‚Äôs trying to prevent overfitting by adjusting for the complexity of the model).\n",
    "\n",
    "4. Why It‚Äôs Important:\n",
    "\n",
    "Model Simplicity vs. Complexity: While high R¬≤ might suggest a good model, it‚Äôs important to ensure that the model isn't too complex. If adding more predictors doesn't significantly improve the model‚Äôs explanatory power (reflected in adjusted R¬≤), it could be a sign that the model is overfitting or not using the most relevant predictors.\n",
    "Generalization: A model that‚Äôs overfitted may have high R¬≤ on the training data but perform poorly on new, unseen data. Adjusted R¬≤ provides a more realistic measure of how well the model generalizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38816c6a-fdab-4a08-af73-0a4c8307a474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29e89ad8-b1f8-4a72-a830-e95f2c525a74",
   "metadata": {},
   "source": [
    "22) Why is it important to scale variables in Multiple Linear Regression ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432cf47c-ad83-461d-9a76-2412a43e0f0c",
   "metadata": {},
   "source": [
    "1. Ensures Comparable Magnitudes of Variables:\n",
    "   \n",
    "In a Multiple Linear Regression model, each predictor variable contributes to the estimation of the regression coefficients. If the predictors are on different scales (e.g., one variable ranges from 0 to 1, while another ranges from 1,000 to 100,000), the larger-scaled variables may dominate the model‚Äôs interpretation.\n",
    "Example: If you're predicting house prices using square footage (which can range in the thousands) and number of rooms (which might range from 1 to 10), the large scale of square footage might overshadow the effect of the number of rooms in the model.\n",
    "Solution: Scaling the variables brings them to a similar range (e.g., standardizing them to have a mean of 0 and a standard deviation of 1), allowing all predictors to be treated equally in the model.\n",
    "\n",
    "\n",
    "3. Improves Model Convergence (in Gradient Descent Optimization):\n",
    "\n",
    "Scaling is crucial when using optimization algorithms like gradient descent to estimate the model‚Äôs coefficients. Gradient descent relies on taking steps in the direction of the steepest descent to minimize the cost function (e.g., mean squared error). If the features are on very different scales, the steps may become uneven, with larger-scaled variables causing larger adjustments in the coefficients and smaller-scaled variables being ignored.\n",
    "Convergence issues: Without scaling, it can take longer for the algorithm to converge or it might even fail to converge to the optimal solution. This is because the optimization process will treat differently scaled features as if they have different levels of importance, which can lead to instability.\n",
    "Solution: Scaling ensures that the optimization algorithm behaves in a more stable manner and converges faster.\n",
    "\n",
    "\n",
    "4. Multicollinearity and Interpretation of Coefficients:\n",
    "\n",
    "Multicollinearity occurs when predictor variables are highly correlated with one another. When predictors are on different scales, multicollinearity can be exacerbated, making it harder to interpret the coefficients and leading to unstable coefficient estimates.\n",
    "Interpretation: If variables are not scaled, the coefficients can be difficult to interpret, as the effect of one variable on the outcome may appear more significant simply because its scale is larger.\n",
    "Solution: Scaling reduces the impact of multicollinearity (especially when combined with methods like Variance Inflation Factor (VIF)) and helps interpret the model coefficients more clearly. In some cases, scaling can even improve the stability of the model by minimizing the influence of highly correlated predictors.\n",
    "\n",
    "\n",
    "5. Regularization:\n",
    "\n",
    "If you're using regularization techniques such as Lasso (L1) or Ridge (L2) regression, scaling is even more important. Regularization penalizes large coefficients to prevent overfitting, and it does so based on the magnitude of the coefficients.\n",
    "Without scaling, variables with larger scales may have larger coefficients simply because they‚Äôre on a larger numerical scale, even if they‚Äôre not necessarily more important for predicting the outcome.\n",
    "Solution: Scaling ensures that the regularization penalties are applied uniformly across all variables, regardless of their original scale. This allows the model to properly shrink the coefficients in a way that reflects the true importance of the predictors.\n",
    "\n",
    "                                                                                                                                                                             \n",
    "6. Improves Numerical Stability:\n",
    "                                                                                                                                                                             \n",
    "Numerical stability refers to the ability of an algorithm to produce accurate results without significant errors due to floating-point precision. When predictors have very different magnitudes, it can cause instability in the matrix inversion process used in solving linear regression models (especially when calculating the inverse of the design matrix).\n",
    "Solution: Scaling the variables reduces the risk of numerical instability by ensuring that all the predictors contribute similarly in magnitude, leading to more stable and accurate computations.\n",
    "                                                                                                                                                                             \n",
    "7. Enhances the Predictive Power of the Model:\n",
    "                                                                                                                                                                             \n",
    "While scaling does not always change the underlying relationships between variables and the target, it can improve the model's predictive accuracy by making sure that the learning algorithm can better learn from the data and treat all features equally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6631ea5e-a3cb-4670-81e7-60967937a929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96a4c2fd-a4ca-4fea-95cb-e6df7a2e6d19",
   "metadata": {},
   "source": [
    "23) What is polynomial regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae89cca-cf9c-4fd4-99d3-c408204ed7e9",
   "metadata": {},
   "source": [
    "Polynomial regression is a type of regression model that extends simple linear regression by allowing for a nonlinear relationship between the independent variable(s) and the dependent variable. In polynomial regression, the relationship between the dependent variable \n",
    "ùëå\n",
    "Y and the independent variable \n",
    "ùëã\n",
    "X is modeled as an nth-degree polynomial rather than a straight line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1659c797-c21b-4ab5-9aba-159eefb07e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4594093d-6cc8-4d07-9004-184ba7deb253",
   "metadata": {},
   "source": [
    "24) How does polynomial regression differ from linear regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfb5e2d-f792-4a48-8fcf-05178500e98b",
   "metadata": {},
   "source": [
    "1. Model Equation:\n",
    "   \n",
    "Linear Regression:\n",
    "\n",
    "The model assumes a linear relationship between the independent variable(s) \n",
    "ùëã\n",
    "X and the dependent variable \n",
    "ùëå\n",
    "Y. The equation is in the form:\n",
    "\n",
    "Polynomial Regression:\n",
    "\n",
    "Polynomial regression is an extension of linear regression, but it allows for a nonlinear relationship between the independent and dependent variables. The model includes higher-degree polynomial terms of the independent variable(s). For a single predictor, the equation can be written as:\n",
    "\n",
    "2. Relationship Between Variables:\n",
    "   \n",
    "Linear Regression:\n",
    "\n",
    "Assumes a straight-line (linear) relationship between \n",
    "ùëã\n",
    "X and \n",
    "ùëå\n",
    "Y, which means that as \n",
    "ùëã\n",
    "X increases, \n",
    "ùëå\n",
    "Y changes by a constant amount. This is appropriate when the relationship between the variables is truly linear.\n",
    "\n",
    "Polynomial Regression: \n",
    "\n",
    "Can capture curved relationships (nonlinear) between the independent and dependent variables. By including higher powers of \n",
    "ùëã\n",
    "X, polynomial regression can fit more complex patterns, such as parabolas or \"S\"-shaped curves, which linear regression cannot \n",
    "\n",
    "3. Flexibility:\n",
    "   \n",
    "Linear Regression:\n",
    "The model is limited to fitting only a linear relationship, making it less flexible when dealing with data that exhibits nonlinear trends.\n",
    "\n",
    "Polynomial Regression:\n",
    "\n",
    "Offers more flexibility because it can model a wider range of relationships. The degree of the polynomial (the highest exponent of \n",
    "ùëã\n",
    "X) determines the model‚Äôs complexity.\n",
    "\n",
    "4. Interpretation of Coefficients:\n",
    "   \n",
    "Linear Regression:\n",
    "The coefficients (\n",
    "ùõΩ\n",
    "1\n",
    "Œ≤ \n",
    "1\n",
    "‚Äã\n",
    " ) represent the change in \n",
    "ùëå\n",
    "Y for a unit change in \n",
    "ùëã\n",
    "X. The slope is constant throughout the data range.\n",
    "\n",
    "Polynomial Regression:\n",
    "The interpretation of coefficients becomes more complex because the effect of \n",
    "ùëã\n",
    "X on \n",
    "ùëå\n",
    "Y depends not only on \n",
    "ùëã\n",
    "X but also on the powers of \n",
    "ùëã\n",
    "X (e.g., \n",
    "ùëã\n",
    "2\n",
    "X \n",
    "2\n",
    " , \n",
    "ùëã\n",
    "3\n",
    "X \n",
    "3\n",
    " ). The relationship between \n",
    "ùëã\n",
    "X and \n",
    "ùëå\n",
    "Y is not constant but varies depending on the value of \n",
    "ùëã\n",
    "X. For instance, the effect of \n",
    "ùëã\n",
    "X might be increasing at some point, then decreasing at another, depending on the degree of the polynomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2d494b-518d-4fd3-871d-1226d4300ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70cb355d-0255-4a3c-ad63-50857acd830e",
   "metadata": {},
   "source": [
    "25) When is polynomial regression used\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7f7d5b-7668-4b7a-a22e-791d1bb42b1f",
   "metadata": {},
   "source": [
    "\n",
    "Polynomial regression is used when the relationship between the independent variable(s) (\n",
    "ùëã\n",
    ") and the dependent variable (\n",
    "Y) is nonlinear and cannot be accurately captured by a simple linear regression model. It is particularly useful in the following scenarios:\n",
    "\n",
    "1. When the data shows a curved or nonlinear relationship:\n",
    "2. When you suspect acceleration or deceleration in the relationship:\n",
    "3. When linear regression underfits the data:\n",
    "4. When you want to add flexibility to the regression model:\n",
    "5. In cases where you need a smooth curve:\n",
    "6. When higher-order relationships are implied by theory or domain knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4489aea-164e-4fcc-a0f2-c5ae2bc84eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c519e97-9db8-49ee-b1a0-d8801ecc5f4a",
   "metadata": {},
   "source": [
    "26) What is the general equation for polynomial regression\u001d",
    "\n"
   ]
  },
  {
   "attachments": {
    "c1690a2d-5714-4d67-b3fa-91f80cd2a535.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtEAAAA4CAYAAAA7HaRkAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAABgeSURBVHhe7d0PUBvXnQfwb+88Y3VSijM5LF9DjjQFy3GcUtf8uboEXWOHxC3gJAbcK1RtsE3qAE5jcNuYcG0hpDc2zThA0lo2tVHoXYLctIDPLrKdWKTjVCJngxO7KJ64yEmukieekTr2II+ZefeetAIhBNaKBST8+8ystbsSsvbtvre/3X1/PsM4EEIIIYQQQsL2D9IrIYQQQgghJEwURBNCCCGEECITBdGEEEIIIYTIREE0IYQQQgghMlEQTQghhBBCiEwURBNCCCGEECITBdGEEEIIIYTIREE0IYQQQgghMlEQTQghhBBCiEwURBNCCCGEECITBdGEEEIIIYTIREE0IYQQQgghMlEQTQghhBBCiEwURBNCCCGEECITBdGEECKD55MBmI4NwH7FI60h0+Jxw37GjIFLTrgpSQkhMYSCaEIICceIDc3rH0DJQQuGrPUoSFmMlA0G2Eak94ls7t4a5BXsQs+QGx+8uhkrFqeg4qhbepcQQqLbZxgnzRNCCJmE9dm7UP+ld9G9We1bcaYe92t3w/XkcXy0O8O3jshgRfXitehc14o/tRVCDQ+MGxdj09F8tP6tHYW3SR8jhJAoRXeiCSHkpuywvOWGeXsBmi9Jq1bmo4jH0+62Dh4OkkgsXAg43+znqSuosNAbONvhuOJdQQghUY2CaEIIuakk5FfrUPj9bcj5grSKB32qeGmWRCADDRcu4/JfG/gcN2JG72H+mr0FRf8iVhAyNff5Luj3d2HAe9Hlgb3XiOaGZhh77XyJkJlH1TlihLOvC5aPpYVxkpD5WCqkB8wSD2xvmWBzSYt+d2cif+X4T0adETesrdtRtceEgU+uQ70yDzsaX0RZegxHKzOwTWEdD24bTG/aJp5MEvlxkB6lx4HHjq6fV6D+kAW2KwuhWa1D7d4G5N8pvR+BGUurT/RYe281bFFencNzsQv12+rRYbXBuVADbUkt9tfnQ71A+oBck6UVF39fDrRLVd750OmugubBHGgCD32PG86L/ehsqcBz1nwYTzRASxcnc2+myuIRJ6zdFjikxXECzlHu8yaYbROPsiUZ+cgQ5cEnBpQ0LMIOTRMe2LcEutW8vCj5DxTdbcXOtE24/spltBf4jkVCZowIokm0G2IdujSWvCyZJd4ex+LifFNCcjJLfnAXG5Q+NcbC6lYljn4uLi6B/20aK3/DIb0fpVwnWdWqZFa8r585hsWKYeZ4o5Qlxq1gdae9n4g9M7JNDn488H0fdDzE3Z7IkrN3sX7pU8xax1YkBLzvPQ6SWdrzFukDUcbWxnKXrWE7TYNs+AZfvjHM+huz+O/ewDpcvo/IN1Np5WKdTySwuNQqdjLi3zbzBg/k8jJiJ+uxeQ8+xq72s13ZfPuKOvgWRIinVRpPm+Rkvv2j6SXKo8AyRqR7YBnEp0SxH4pZR3Ax9HE/63yjk3U8X8yyvrWTdX4srSdzZybLYkcHKxbHz7KJx0dW42iOZJbnV7CEwPcTxN+ksTqr7/2hPRu8v2VoTxp/P4s12XzrxfmyKTOOpe0ZkpYJmTkURMeYYeMGqVBJYFVmaWUoN3ghyIOCFVs72ZB0/oxqNwZZU3YyKz0SfGrvYaVie7f2SMsxZDa2yVw1eqIpNobY0dadLDkukeXusTCXCEyjlYunSXLgiVDyYRNL49uW1aLACVHBtBrcw4P77DpmieIA2nWklF8oNLHBoG0ZDTrs0oqIOdjeB33pGXdfXYiLeRdre5y/l1rOOj8MrxA6+YwIzHNZGwXSc2cWy2Lf/hbHEL+4uiqtDGB5LpkH17ms6dTEjDbscvHQfph1FPG/3xLwm652sA38OzeEyuOEKIzqRMcY1bqNyPHOeWD4g9k7N5EbpqdK8Pqjh/CnV/KRFANPtOwvl8CQfxit6yZ5VOh2h3x8rJi3KrD4KZO0oIxZ2absLaiU6o92HeyA0zfr4zZh0+MGZL/+PrqfzkB8pI/vg5i3LUbFMWlBER6YdlQBLx5G5VJpVRCXS4G9r1BauY9uQsmbW9B3ohYZfNd6pr0f7dCvWTvWYFEJ10zYvgP4ZVclNCG3xQXXVWk2Ymrotub7Zi81Y987vlk/20u5qPi0AX3vtiD/nlCFkAdu5/i+oe9OSuL/mtH8ms23IlIzkJ+jUqyWWxLt5kqIPc5zJAzGcTnSm882HMzGofe7Ufm1ib9FFR8P1Ugv/niUf8/qVGkt1/tHmPhZcuM6BU58t8pxRCJGQXSsuS0PG/N8s572bphD9FErTl4Fth/h+Cs5mKQYjC7XjKhp1KLxaY20IsBFG87yF/XSpZjRawHPMDxK9vc7a9ukgW6L9H/0GtD5iW8WHht255fjcv3xyU+GEbru8WBYybQ6vxtVH1bihbwQv9PWDxFOaTS+U+30KJBWHzRj02uP4PDvdFJwakPzNr3Uu0Tkrl9zAwqmqW1PFeyVLyA/VJKe86YolimQpKpHdSj0zvGLeuPYRb27exNyD2Sie9Ignv/Foc24KyUFd22fGKS4rk4zTFM6P0ermC23JMt1KFvumzW/2jl6YevhZULutstoONGKnKmy5HsW9PJjOSfb327BA2O7EcjbiLzbnDDtN42/WJbrVjmOSMQoiI45KuQ9Jt398RjQfco36yeu3nPfyMHxKU5e0cZpNMCy+bvQhvi9A6/qeZiSim3fDbjTEANmc5uSCrb4ejeAFc0HeYAkBgV5OB1djx9G9/dDnAyjjPVAMzRbdUGNYwU3jAf5CTGen2iVuKvETSutPjAg73EDVPFm1G+vQMU2MVXD8I8afhqPJlbse0mDJ0tCNIh0G6F/jSdpSRkPMqR107EgB7rNvn3j2b8Pxmu+MmjFU8DL5sYpGwiqFi/hpZkKGaljqTdkF5cjSdAVxlZ+ny9mvyxOQtETUqPcvmboz/NXfqH6UFYXiv6nG7pJnkz52U/xIFmlReY90goeUpu7gZzH8qA6o0ezMylEuUKIgqRqHSSW3JDqpokpoC6Y60g5S04uZT1RXE9zIlGnLYFVneKzN4aZ69xJ1vlGD+u3u5jjVB3LEnVUD0ysbam4I6Xj69VNy2xvE///viMdDwmlrGpLIkvk2zJTh0HPljhWekRamLZ+Vpecy9pEY7NhFxs63cPT6iQbdLjYoLHY25CpyqzklkSaVkOsSTTI8+e7gCn5Z2ONoSIjGkKlsaYPpcXpOl3Hkr/VxnxJOsT6TZ2s0zzIHJ8O8m1PVL4x5Lk6tkJKizXPVLGs20PUbQ/JxXq2rmBZW5pYh7dhYS7f38ms2KhAA2hF83MUi+lyS3K1gxVLx0/CE1WsNDExRH3s0ERZlPDMSWlJ8OXTNc/UsWLd3gntAWSbieOIl3MOb9ryfGnqj+62KuSmKIiOURMaZNiaZJy8oomFVSXywP+Gg7XljwUm/imrcRYCaEHRwnIOtimg0VzCE50zFkALigbRjjaWm9nET30WtjNxYlqVHpmBxkGzmFbhUTaIdhzI9fVMYN3Jg9KgNL2dH5chGnBNT0ADw7g0tktmGTTsGmQnRUDBA32XUrubgugIzF1ZPHY+S2ClXTJy5FWXryefcfgFAL8IV+RQUjJ9P7Wwpu8ke7fT27OW6KFkVdUM5Ecym6g6R4zSPqqT6qV1ofO/jdi0ZheW/nbyhllhcxpRcm8KUiKdvmeUVwftTA86Vz+C7AVq6P6rD91t7WhvO4S33/8Ib/9Ug4GfV8Pgr7saK+Zim7KLoJNqPHiuX8dC32zU87zdhcF12UhCBmrffRuHvGnVjb6/XvD28Wosew5WpeskxmhahceD3qODyM9OAtJr8a75EE9PnqaH+/DRX9pRuICXFT9TenxFNdZ/VyvNe2TXIVXFa6B9LJ//Zg3ilam1QyIxh2WxttB/PvPg+nUZOfK2eKgmVD1RIV7N10tL0cDdV48HvrgWNefW45AYYOjCBVz4C5/ebUQODW8f26RgmsQaqQu70bsEe5S7SzD8qYM5HJFNLplX1aN3zUIRdynFVXt1UF+90qPGntNDUXnnKqJt8nKxoQ8juy/qMBazZOlYiItbw/bOYBdhSt6JtlSLR7fSQrBTvjvGuQfGP9733bn0VfmIZPfPZlqFR8k70f67idJiEEu11IVcYJJK+enkOfn518tlYXUBVV3GP16fIwrl5+EPxWP3k2F1E+qwirvpQzc/Jm+4vFVses4p8AwkKsqtabrhYB3SHVrv9OBeb1WkqKBE+rp8Xe5R143zE41YGMNMZZ9HwWt8Zl0rPnq9MDZ64hjHA+PG+zH4kwuoXSmtGseETZ8vgHFlA94zS10hfWJEydpdWFRVi5zPDWDfz83I6Twe1h34yUeu4043ocSaifYfZEorgi1BZl5GGKO8ydymEQ/cV+zof8sEQ2MNjF89hL/rfZ0YhsvbkKsMaO3JxK5/rYa4z5j04z68VxNhc7epRhTjLL8ugSWjHdu+Kq0IFvaIiAOoT6nHsv5DKAx1N+ZiM9K/UgNbCU+TV0SauGHalotmFCHvSzZ0tBhgja9Et4wR7hRPq3BNMcofeEp3/mg3UP1LrF8srQqi0miRszyMjTxTj5T/XIb3eHkQ6k6c/aV03F9rg+53f0fLQ3zFBwaUbDcjs2Q9kq6aULPdAPUv+nC8PMz0EA0z16Sj4/E+1NofQMF+sYX5aP1be+h9qqAZz8/XeFnzz5vQJebzWnH5t6HT1Oudaix+WO/dv/m/mXqkPOuzd2Hty24+p0XLhW7obpJVorLcktZOH8/TZSuwCa04vmoX0nd4cyR2/Pk91Eq9dsy0mU5f8/bFyBP5YmUlWn+YGfDkK9x9Q6IZVeeIWQOwvOWb067LjsEAWjgLy6lsZN4vLQaTulQa44ThyU1w/PAwWjbnI//bteje+xXUr+HBUNR0QyRzm670Qr/HhMt3LOFFqnzjuoJarsOTUveH9oMd/AiJcs4BWO/QImOyYEvq3s7P2V6C8gXPw9hUibKnW3D8Xb7NHzQjr9gQVhWimE6rMDkHrFi0OmPSYM/XvZ0fz0/bK9DlWIbsAp6fNregvUrNg7wC1IteEm5mxI2up3Khz+jG4ac1yAno8/f1o9Psoi7aiGoD0mxICxaGXS0o/nOLpLloIrcsVoIHtl/motzZ4O2OVVPyJL/8EuwwGOdLjrSiu13KCxc7sHNnFar8UwMvd6773iIxzHs/msQe6fGaaMijWKt+yaxV5xC9CBR1TP74s6vU93jY/wjRO3pd8vhhZ6V0KDdJy5FS6rGo3G0aJR7p8/0p5zeEakw62mjuJiNaToNS1TnE6JtT9Wwx2ChG1hurziH+X7E8tq9FbwLSY9KbPf+do7QKj1LVOUR6BOWPcQbZrlWB6eVvQDaWfv40v3l+cvH9EdyzSUADw7l+JK9odQ4Lc4TRg4JroEdWdY6TYY7iOKU5L7ci5xv1c/yImqMNDBOq2Mlo6LVi2unr70lL+fM0iQ50JzpGiQZZ3qENxvWRqQCnEZuzspD1b5FNaU+F37DQ28enGHVKWh7PA+NrRv4aD93jUj+i58SdyUVYFHjbXb0E4gm45fx0h7tQhuxtipQYYS9UY9LRUfk80O818n+jV++bJixaNNldORs6Doi7ploUPuR73p39RAMKC3agcDTpVFgYTpWBeZBW4emF+WhQ/gh0vgOGD/hrdiEe9iapGrrfXcbly/4qBU6Yj/A0jy+D7htieXKhB3QKGMHQ3+dvjFPdo0X+Y+E9co//co63QeeUd6yFBfFIfSgf2pCjOM6NSMotZ58e+v1m2EXGGXFj4Jge9Q16mM6KqipTE9Wq1jYuxaGg8QxGRzD06LHvD/PpaYYGSV+QZsm8QkF0jDpr6fXNPJojDR6hEHUh2kWr4UintsIwO7f3wNo7APyfI3TQ/c5z2N7Ni+1vt6L2a75V9ouTP1C02QIfU88V+dsUEREUrtgE6N8PMcKeBkX/LtVY7N4bxT2bDMByjO/Tj0NfcjkPVmP3JSC1vhG6O33rVF+rROtvasfqP4+Y0XuYv44GhSHMi7QK0xkLemCHPWSSOmH40W7+bioaXgwY2GaBCqoFHrgvDaCrYTNP8xy0nGhExhRBo+2lB5D+RhH6Tkwc0Em1bv3oI/lmHmCRWBBBufVODcp7M7HkbCHuL6hARXEN7HeuR9k33ajJypqyOtBou4T3Q4xGuLwIRf6h+X8VXjWt6JYKbbZ4tcGm5LD+JGpQEB1T+MnO6YTzkhF723xX6Zo7F8HJ17lj7qK9F+ZjaqgHarDz6Pg7F6I7oLXf0kNV0o73wx26PCrqRCu8TYGuufl+tsG8vwLpXyyA8ZoWj9wnjogg/HOq5Vrp+61o/rXZd3xc866IHpd6YfKoEd9ahWZxdzSA81AJsraZkVHfh2Ohhh+W2F6qhn6hFi2BQaEw39IqTOJuokcdD/1PmmELzA8jThi/l4WKUxlo+POxiY1wr9vR/792fgGdhCVfiIfHHXwn0Vfu2M90oX5DCtJrB6B5kAdQE+pz8s9dXYpUqWGaZ38zDJd4eeV0T0x7EkXkl1umA3Zs/EEqVB6+ZweGka9vQf5y/h0rU/FlfgE1FPRg0HOFHwfnzdBvS8ddG41wP/gIv4SdeFR4rqiQmi39L33NaOqVjp+oafMilxq6Fxt4KG1DU6MJganrudgFw7HYv0y45UnVOkgMGHx+ha++WKhpqwL14maTf1Q1WxvbkJzA50tZeWUpy01NYAnLilndmxNrVA7tEfU1g+uWSXXOplsvUIm6hRFs05ip6kT3sPLg/e2dgusCT/Y5Pt1Xx5TqBFGJOtGiPrSoX+ky72RpCQksq6icp9UGlpXI0+rr5aztJt1/ufj+SkwsZh0TuoyKrrQKjxJ1ov2jzbnYyZ+ksYSELLahkqdpURZLFOlb2cYGw+hRzfHrNTwNEn2j1kmGWrImphGfguvHTvY5MRUbFaj/K4dSdYWj3RyVW8PevkXFaKNx47vFE98V3G7FVB7ymIiTRtUcNdnn+LTi+dnNkaMUOo5c1iZWvIxvy7JcVsrz5Yav87RdVcr2WhXo5pDMKQqiyZwQJ9yxwleMMBVGw0Rv45bQQfSk/ZuGS4HCMqJtGhVBw8I5okQQ3bM14DtEP8X+tAon1rI1sTWrAoauDjlqWSxRIojmFwViNEJ/OvA08TX2nbovbdGIeNzxKfKBCFye6JRWxCiFgp+oN5fllrehtzRMuMR7oyO5jofX84TCx9Foo33FBjggc42qc5A5IOrg2aDNkOqjQowwpYaaT/FTNRS77yvQBNf5vGSDqA3w5aX+74qQ6rMhRr6SI8JtikELVSp8dlppJepDa6H19zO9ICCtbtbWym1CxbMuvHCicbRudFfldph8szFr4W18Y6aTpqI+9GotUv3fwb9PpKd6qpHbztcj/YspuOubzTxXBbl2PbarYEw7P8eIOSy3PKfNsCEPOenSCr5k2GdD0veLkDoyAP3BedBNncLHkeoOX9qqaWjOeYOCaDIHRB28wMI3TPcUYUu6B/1nA6LoITtsqjLoxMAR0/GNFlx+Rd4gJ+NFuE0xSNt02TdQR6REfeg7cqANrwXqGLcZ1doqDKqdMNRWoGKbmEqw275sQgO32JKEshPHpZ5CIiPqQy96SBtmo15JPD+Z8xd1hmb075yXfOF0fmHe5MF3LJh2fo4Rc1huid51kB1w4XbJBNMlNYq+qYH7D7vR+7nJ2zPEjFvlOCIRoyCazD5x1+yhR5AtO/BRo+xXDUBtAaqP2WA/o0fJk2ZsOVQL7VwHURFvkxk196YgJSUdNaJF+2slSBHLG/QT7w7OEx6rGY512bJHPTM9mwf9RTus7QYYDvqnLgz8092yv2t+EXcTHd7u1WS5swwv/yIDqrNmGH7fha79FVi7w4qMHx/Hy1OMuEfmkYjLLTtsp4GMvIfHLtzu0CA1HhjqqsYmi46OIXJLoGG/yazz9Omx+9P1qF0n91akxOOGjQdiNmigzdDcvArALJj2Nt1C7L+vQc/dDSgLObwwkc+OrtoeJP20bOyuoBzXnBg4ZeHfkoTM1alQz7PqR2Ry0ym3vL24BPctPeKBd/UdFECTWwMF0YQQQgghhMhE1TkIIYQQQgiRiYJoQgghhBBCZKIgmhBCCCGEEJkoiCaEEEIIIUQmCqIJIYQQQgiRiYJoQgghhBBCZKIgmhBCCCGEEJkoiCaEEEIIIUQmCqIJIYQQQgiRiYJoQgghhBBCZKIgmhBCCCGEEJkoiCaEEEIIIUQmCqIJIYQQQgiRBfh/88XRvK8O0P4AAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "id": "af7a6fd8-e455-401b-91d5-de7e15c92b4b",
   "metadata": {},
   "source": [
    "![Screenshot 2025-01-28 220315.png](attachment:c1690a2d-5714-4d67-b3fa-91f80cd2a535.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64aea51-e653-4aaa-b71c-9a5495861329",
   "metadata": {},
   "source": [
    "Y=Œ≤ \n",
    "0\n",
    "‚Äã\n",
    " +Œ≤ \n",
    "1\n",
    "‚Äã\n",
    " X+Œ≤ \n",
    "2\n",
    "‚Äã\n",
    " X \n",
    "2\n",
    " +Œ≤ \n",
    "3\n",
    "‚Äã\n",
    " X \n",
    "3\n",
    " +‚ãØ+Œ≤ \n",
    "n\n",
    "‚Äã\n",
    " X \n",
    "n\n",
    " +œµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0fd9e0-9763-41ff-96a5-dc1e41960b27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a184e487-7fc0-47f4-8d07-d3f7fe880998",
   "metadata": {},
   "source": [
    "27) Can polynomial regression be applied to multiple variables ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2423c0e-dd77-446d-b81d-c9f3202457ff",
   "metadata": {},
   "source": [
    "Yes, polynomial regression can be applied to multiple variables. When applied to multiple predictors (independent variables), it is called multiple polynomial regression. In this case, the model extends the idea of polynomial regression to handle more than one independent variable, allowing for polynomial terms that involve multiple variables and their interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83053d08-39d8-4746-8368-77b6b86161e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22863925-6eb6-448c-99be-49f733c99c97",
   "metadata": {},
   "source": [
    "28) What are the limitations of polynomial regression ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998eb26c-f7d4-46bd-821f-87eb0fcf5156",
   "metadata": {},
   "source": [
    "1. Overfitting:\n",
    "\n",
    "High-degree polynomials can lead to overfitting, especially if the degree of the polynomial is too high. Overfitting occurs when the model fits not only the underlying pattern in the data but also the noise or random fluctuations. This leads to a model that performs well on the training data but poorly on unseen data (low generalizability).\n",
    "Example: A 10th-degree polynomial might perfectly fit the training data, but it may be very sensitive to small variations in new data, resulting in poor predictions.\n",
    "\n",
    "2. Complexity and Interpretation:\n",
    "\n",
    "As the degree of the polynomial increases, the model becomes more complex and harder to interpret. In particular, the coefficients for higher-degree terms (e.g., \n",
    "ùëã\n",
    "3\n",
    "X \n",
    "3\n",
    " , \n",
    "ùëã\n",
    "4\n",
    "X \n",
    "4\n",
    " ) may not have an easily understandable or intuitive meaning, making the model harder to explain to stakeholders.\n",
    "Example: A cubic polynomial regression with multiple terms might not provide clear insights into how each variable influences the outcome because the relationship is now embedded in higher-order terms.\n",
    "\n",
    "3. Extrapolation Issues:\n",
    "\n",
    "Polynomial regression models are sensitive to extrapolation, especially when higher-degree terms are involved. This means that if you try to make predictions outside the range of the training data (i.e., extrapolate), the model can produce unrealistic or erratic predictions.\n",
    "Example: If you're using polynomial regression to predict growth, and you extrapolate to a point far beyond the range of your data, the model may predict values that grow extremely fast or decline sharply, which may not reflect the real-world behavior of the system.\n",
    "\n",
    "4. Multicollinearity:\n",
    "\n",
    "Polynomial regression often involves creating new features by raising the independent variables to higher powers (e.g., \n",
    "ùëã\n",
    "2\n",
    ",\n",
    "ùëã\n",
    "3\n",
    "X \n",
    "2\n",
    " ,X \n",
    "3\n",
    " ). These new features can become highly correlated with the original features, leading to multicollinearity. Multicollinearity can make the model unstable and affect the reliability of the estimated coefficients, making it difficult to interpret the effects of individual predictors.\n",
    "Example: In a quadratic model, the variable \n",
    "ùëã\n",
    "2\n",
    "X \n",
    "2\n",
    "  might be highly correlated with \n",
    "ùëã\n",
    "X, which could make it hard to isolate their individual effects.\n",
    "\n",
    "5. Computational Complexity:\n",
    "\n",
    "As the number of predictors or the degree of the polynomial increases, the computational complexity of fitting a polynomial regression model grows. This can become an issue when dealing with large datasets or high-degree polynomials, as the model becomes computationally expensive and harder to train efficiently.\n",
    "Example: A polynomial regression model with many predictors and high-degree terms may require significant computational resources, especially when used with a large dataset.\n",
    "\n",
    "6. Sensitivity to Outliers:\n",
    "\n",
    "Polynomial regression is sensitive to outliers. A single outlier can drastically change the fit of a high-degree polynomial, causing the model to be overly influenced by that point. This results in a model that may not represent the true underlying relationship.\n",
    "Example: In a dataset with a few extreme values, a high-degree polynomial might bend to fit those outliers, even though they don't represent the general trend in the data.\n",
    "\n",
    "7. Not Always the Best Fit for Complex Relationships:\n",
    "\n",
    "While polynomial regression can capture some nonlinear patterns, it doesn't always model all types of complex relationships well. For example, piecewise nonlinear relationships or relationships with interactions between variables that don't fit a polynomial form might not be well-represented by polynomial regression.\n",
    "Example: If the data follows an exponential or logarithmic relationship, a polynomial regression model may not capture the underlying trend as well as other specialized models.\n",
    "\n",
    "8. Limited to Polynomial Forms:\n",
    "\n",
    "Polynomial regression is limited to fitting polynomial functions. This means it may not be able to model relationships that are better represented by other forms of nonlinear functions, such as logarithmic, exponential, or sigmoidal relationships.\n",
    "Example: Modeling a population growth model that follows an exponential growth pattern could be better suited for exponential regression, rather than polynomial regression.\n",
    "\n",
    "9. Multivariable Polynomial Regression Can Get Very Complex:\n",
    "\n",
    "When applied to multiple predictors, polynomial regression can become very complex, especially as the degree of the polynomial increases. For example, with multiple variables, you must include interactions between variables (e.g., \n",
    "ùëã\n",
    "1\n",
    "ùëã\n",
    "2\n",
    "X \n",
    "1\n",
    "‚Äã\n",
    " X \n",
    "2\n",
    "‚Äã\n",
    " , \n",
    "ùëã\n",
    "1\n",
    "2\n",
    "ùëã\n",
    "2\n",
    "X \n",
    "1\n",
    "2\n",
    "‚Äã\n",
    " X \n",
    "2\n",
    "‚Äã\n",
    " , etc.), which increases the number of terms exponentially.\n",
    "Example: For three predictors and a quadratic polynomial, you would have 10 terms, but for a cubic polynomial, the number of terms increases to 20. This can quickly make the model hard to manage and prone to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fecd5c-8e54-47a7-8612-c5437dd3a6f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12da6046-45ca-4f20-81b7-a66b5d8b8d6d",
   "metadata": {},
   "source": [
    "29) What methods can be used to evaluate model fit when selecting the degree of a polynomial ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8ef9f3-85da-44d6-bf0c-b3044a1c7181",
   "metadata": {},
   "source": [
    "Cross-validation: Ensures the model generalizes well to new data.\n",
    "\n",
    "Adjusted R¬≤: Penalizes for unnecessary complexity and helps select the best degree without overfitting.\n",
    "\n",
    "MSE or RMSE: Measures the fit of the model and helps track errors.\n",
    "\n",
    "Training vs. Validation Performance: Compares performance on both sets to identify overfitting.\n",
    "\n",
    "AIC/BIC: Provides a balance between model fit and complexity, helping to prevent overfitting.\n",
    "\n",
    "Residual Plots: Offers visual diagnostics to check if the model fits well.\n",
    "\n",
    "Learning Curves: Assesses model performance as training data size increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffce1a2a-f77f-4f04-bc51-ac929eafe077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ee5c61f-6eb3-489e-be15-e8ab4a859ffc",
   "metadata": {},
   "source": [
    "30) Why is visualization important in polynomial regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a09ce84-f11c-4b44-b772-d830bfaebcd6",
   "metadata": {},
   "source": [
    "Understanding Relationships: \n",
    "It helps visualize the nonlinear relationships between variables and assess if the polynomial model appropriately captures the data's trends.\n",
    "\n",
    "Assessing Model Fit:\n",
    "Visualizing the fitted polynomial curve alongside the data allows you to evaluate how well the model matches the data and whether it's underfitting or overfitting.\n",
    "\n",
    "Detecting Overfitting:\n",
    "Residual plots and visualizing model performance on training and validation data can help identify overfitting by showing if the model is too complex for the data.\n",
    "\n",
    "Detecting Underfitting:\n",
    "A simple model (low-degree polynomial) can be visually checked for underfitting if the curve doesn't capture the data's trend.\n",
    "\n",
    "Identifying Nonlinear Patterns:\n",
    "Visualization reveals whether the data follows a polynomial relationship or if another model might be more appropriate.\n",
    "\n",
    "Multivariable Visualization: \n",
    "In models with multiple predictors, 3D plots or heatmaps help visualize complex relationships and interactions between variables.\n",
    "\n",
    "Diagnosing Polynomial Terms:\n",
    "Visualization helps you understand the contribution of each polynomial term and decide if higher-degree terms are necessary.\n",
    "\n",
    "Evaluating Polynomial Degrees: \n",
    "By comparing models with different polynomial degrees, visualization helps choose the optimal degree without overcomplicating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aea8c2b-61ad-406e-8f1d-1c53085330f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e233e898-9492-4516-a2bc-3fa8600d5bd5",
   "metadata": {},
   "source": [
    "31) How is polynomial regression implemented in Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "62b44985-3c47-4852-bad1-b8cde72c2398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).reshape(-1, 1) \n",
    "y = np.array([1, 4, 9, 16, 25, 36, 49, 64, 81, 100])  \n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X) \n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, y)\n",
    "\n",
    "y_pred = model.predict(X_poly)\n",
    "\n",
    "plt.scatter(X, y, color='blue', label='Actual Data')\n",
    "plt.plot(X, y_pred, color='red', label='Polynomial Regression Fit')\n",
    "\n",
    "plt.title('Polynomial Regression')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcef00b-f224-499c-92e7-9c4740ded044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
